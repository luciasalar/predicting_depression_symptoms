0.590983606557377,"{'clf__classifier__C': 0.1, 'clf__classifier__gamma': 0.5, 'clf__classifier__kernel': 'linear'}","                   0          1  accuracy   macro avg  weighted avg
f1-score    0.391753   0.638037  0.546154    0.514895      0.554679
precision   0.358491   0.675325  0.546154    0.516908      0.568089
recall      0.431818   0.604651  0.546154    0.518235      0.546154
support    44.000000  86.000000  0.546154  130.000000    130.000000",2019-12-06 22:25:30.566473,sklearn.svm.SVC,['liwc'],1000
0.5778142076502732,"{'clf__classifier__C': 0.1, 'clf__classifier__gamma': 0.5, 'clf__classifier__kernel': 'linear'}","                   0          1  accuracy   macro avg  weighted avg
f1-score    0.400000   0.682353  0.584615    0.541176      0.586787
precision   0.391304   0.690476  0.584615    0.540890      0.589218
recall      0.409091   0.674419  0.584615    0.541755      0.584615
support    44.000000  86.000000  0.584615  130.000000    130.000000",2019-12-06 22:25:50.878560,sklearn.svm.SVC,"['liwc', 'sentiment', 'topic', 'moodChange']",1000
0.7055913978494623,"{'clf__classifier__C': 0.1, 'clf__classifier__gamma': 0.5, 'clf__classifier__kernel': 'linear'}","                   0     1  accuracy  macro avg  weighted avg
f1-score    0.842105   0.0  0.727273   0.421053      0.676236
precision   0.786885   0.0  0.727273   0.393443      0.631893
recall      0.905660   0.0  0.727273   0.452830      0.727273
support    53.000000  13.0  0.727273  66.000000     66.000000",2019-12-06 22:31:18.486116,sklearn.svm.SVC,['liwc'],1000
0.7320430107526882,"{'clf__classifier__C': 0.1, 'clf__classifier__gamma': 0.5, 'clf__classifier__kernel': 'linear'}","                   0     1  accuracy  macro avg  weighted avg
f1-score    0.831858   0.0  0.712121   0.415929      0.668008
precision   0.783333   0.0  0.712121   0.391667      0.629040
recall      0.886792   0.0  0.712121   0.443396      0.712121
support    53.000000  13.0  0.712121  66.000000     66.000000",2019-12-06 22:31:27.249106,sklearn.svm.SVC,"['liwc', 'sentiment', 'topic', 'moodChange']",1000
0.7647311827956988,"{'clf__classifier__class_weight': 'balanced', 'clf__classifier__max_depth': 100, 'clf__classifier__max_features': 'auto', 'clf__classifier__max_leaf_nodes': 300, 'clf__classifier__n_estimators': 100, 'clf__classifier__n_jobs': -1, 'clf__classifier__random_state': 300}","                   0     1  accuracy  macro avg  weighted avg
f1-score    0.890756   0.0   0.80303   0.445378      0.715304
precision   0.803030   0.0   0.80303   0.401515      0.644858
recall      1.000000   0.0   0.80303   0.500000      0.803030
support    53.000000  13.0   0.80303  66.000000     66.000000",2019-12-06 22:37:12.606377,sklearn.ensemble.RandomForestClassifier,['liwc'],1000
0.7647311827956988,"{'clf__classifier__class_weight': 'balanced', 'clf__classifier__max_depth': 100, 'clf__classifier__max_features': 'auto', 'clf__classifier__max_leaf_nodes': 300, 'clf__classifier__n_estimators': 100, 'clf__classifier__n_jobs': -1, 'clf__classifier__random_state': 300}","                   0     1  accuracy  macro avg  weighted avg
f1-score    0.890756   0.0   0.80303   0.445378      0.715304
precision   0.803030   0.0   0.80303   0.401515      0.644858
recall      1.000000   0.0   0.80303   0.500000      0.803030
support    53.000000  13.0   0.80303  66.000000     66.000000",2019-12-06 22:37:31.001505,sklearn.ensemble.RandomForestClassifier,"['liwc', 'sentiment', 'topic', 'moodChange']",1000
0.7647311827956988,"{'clf__classifier__C': 0.1, 'clf__classifier__gamma': 0.5, 'clf__classifier__kernel': 'linear'}","                   0     1  accuracy  macro avg  weighted avg
f1-score    0.890756   0.0   0.80303   0.445378      0.715304
precision   0.803030   0.0   0.80303   0.401515      0.644858
recall      1.000000   0.0   0.80303   0.500000      0.803030
support    53.000000  13.0   0.80303  66.000000     66.000000",2019-12-06 22:42:44.752309,sklearn.svm.SVC,['liwc'],5000
0.7580645161290323,"{'clf__classifier__C': 0.1, 'clf__classifier__gamma': 0.5, 'clf__classifier__kernel': 'linear'}","                   0     1  accuracy  macro avg  weighted avg
f1-score    0.890756   0.0   0.80303   0.445378      0.715304
precision   0.803030   0.0   0.80303   0.401515      0.644858
recall      1.000000   0.0   0.80303   0.500000      0.803030
support    53.000000  13.0   0.80303  66.000000     66.000000",2019-12-06 22:42:54.213583,sklearn.svm.SVC,"['liwc', 'sentiment', 'topic', 'moodChange']",5000
0.5762820512820512,"{'clf__classifier__C': 0.1, 'clf__classifier__gamma': 0.5, 'clf__classifier__kernel': 'linear'}","                   0          1  accuracy  macro avg  weighted avg
f1-score    0.697248   0.476190  0.616279   0.586719      0.602142
precision   0.633333   0.576923  0.616279   0.605128      0.609064
recall      0.775510   0.405405  0.616279   0.590458      0.616279
support    49.000000  37.000000  0.616279  86.000000     86.000000",2019-12-06 22:47:50.120805,sklearn.svm.SVC,['liwc'],5000
0.5864102564102565,"{'clf__classifier__C': 0.1, 'clf__classifier__gamma': 0.5, 'clf__classifier__kernel': 'linear'}","                   0          1  accuracy  macro avg  weighted avg
f1-score    0.707965   0.440678  0.616279   0.574321      0.592969
precision   0.625000   0.590909  0.616279   0.607955      0.610333
recall      0.816327   0.351351  0.616279   0.583839      0.616279
support    49.000000  37.000000  0.616279  86.000000     86.000000",2019-12-06 22:48:01.257043,sklearn.svm.SVC,"['liwc', 'sentiment', 'topic', 'moodChange']",5000
0.5762820512820512,"{'clf__classifier__C': 0.1, 'clf__classifier__gamma': 0.5, 'clf__classifier__kernel': 'linear'}","                   0          1  accuracy  macro avg  weighted avg
f1-score    0.697248   0.476190  0.616279   0.586719      0.602142
precision   0.633333   0.576923  0.616279   0.605128      0.609064
recall      0.775510   0.405405  0.616279   0.590458      0.616279
support    49.000000  37.000000  0.616279  86.000000     86.000000",2019-12-06 22:53:41.764021,sklearn.svm.SVC,['liwc'],5000
0.5864102564102565,"{'clf__classifier__C': 0.1, 'clf__classifier__gamma': 0.5, 'clf__classifier__kernel': 'linear'}","                   0          1  accuracy  macro avg  weighted avg
f1-score    0.707965   0.440678  0.616279   0.574321      0.592969
precision   0.625000   0.590909  0.616279   0.607955      0.610333
recall      0.816327   0.351351  0.616279   0.583839      0.616279
support    49.000000  37.000000  0.616279  86.000000     86.000000",2019-12-06 22:53:52.867144,sklearn.svm.SVC,"['liwc', 'sentiment', 'topic', 'moodChange']",5000
0.5964102564102565,"{'clf__classifier__C': 0.5, 'clf__classifier__n_jobs': -1, 'clf__classifier__penalty': 'l2', 'clf__classifier__random_state': 300}","                   0          1  accuracy  macro avg  weighted avg
f1-score    0.696429   0.433333  0.604651   0.564881      0.583236
precision   0.619048   0.565217  0.604651   0.592133      0.595888
recall      0.795918   0.351351  0.604651   0.573635      0.604651
support    49.000000  37.000000  0.604651  86.000000     86.000000",2019-12-06 22:54:10.896867,sklearn.linear_model.LogisticRegression,['liwc'],5000
0.5864102564102565,"{'clf__classifier__C': 0.5, 'clf__classifier__n_jobs': -1, 'clf__classifier__penalty': 'l2', 'clf__classifier__random_state': 300}","                   0          1  accuracy  macro avg  weighted avg
f1-score    0.717949   0.400000  0.616279   0.558974      0.581157
precision   0.617647   0.611111  0.616279   0.614379      0.614835
recall      0.857143   0.297297  0.616279   0.577220      0.616279
support    49.000000  37.000000  0.616279  86.000000     86.000000",2019-12-06 22:54:28.614340,sklearn.linear_model.LogisticRegression,"['liwc', 'sentiment', 'topic', 'moodChange']",5000
0.6873076923076923,"{'clf__classifier__C': 0.1, 'clf__classifier__gamma': 0.5, 'clf__classifier__kernel': 'poly'}","                   0          1  accuracy  macro avg  weighted avg
f1-score    0.690909   0.451613  0.604651   0.571261      0.587956
precision   0.622951   0.560000  0.604651   0.591475      0.595867
recall      0.775510   0.378378  0.604651   0.576944      0.604651
support    49.000000  37.000000  0.604651  86.000000     86.000000",2019-12-06 23:21:24.523168,sklearn.svm.SVC,['liwc'],1000
0.6516666666666666,"{'clf__classifier__C': 0.7, 'clf__classifier__gamma': 0.001, 'clf__classifier__kernel': 'poly'}","                   0          1  accuracy  macro avg  weighted avg
f1-score    0.719298   0.448276  0.627907   0.583787      0.602696
precision   0.630769   0.619048  0.627907   0.624908      0.625726
recall      0.836735   0.351351  0.627907   0.594043      0.627907
support    49.000000  37.000000  0.627907  86.000000     86.000000",2019-12-06 23:42:17.355317,sklearn.svm.SVC,['liwc'],1500
0.6466666666666666,"{'clf__classifier__C': 0.1, 'clf__classifier__gamma': 0.001, 'clf__classifier__kernel': 'poly'}","                   0          1  accuracy  macro avg  weighted avg
f1-score    0.725806   0.291667  0.604651   0.508737      0.539025
precision   0.600000   0.636364  0.604651   0.618182      0.615645
recall      0.918367   0.189189  0.604651   0.553778      0.604651
support    49.000000  37.000000  0.604651  86.000000     86.000000",2019-12-07 00:03:32.170879,sklearn.svm.SVC,['liwc'],2000
0.6416666666666666,"{'clf__classifier__C': 2.0, 'clf__classifier__gamma': 0.0001, 'clf__classifier__kernel': 'rbf'}","                   0          1  accuracy  macro avg  weighted avg
f1-score    0.728682   0.186047  0.593023   0.457364      0.495223
precision   0.587500   0.666667  0.593023   0.627083      0.621560
recall      0.959184   0.108108  0.593023   0.533646      0.593023
support    49.000000  37.000000  0.593023  86.000000     86.000000",2019-12-07 00:26:09.743991,sklearn.svm.SVC,['liwc'],5000
0.6770512820512821,"{'clf__classifier__C': 1.0, 'clf__classifier__gamma': 0.001, 'clf__classifier__kernel': 'poly'}","                   0          1  accuracy  macro avg  weighted avg
f1-score    0.672727   0.419355  0.581395   0.546041      0.563718
precision   0.606557   0.520000  0.581395   0.563279      0.569318
recall      0.755102   0.351351  0.581395   0.553227      0.581395
support    49.000000  37.000000  0.581395  86.000000     86.000000",2019-12-07 00:46:48.683211,sklearn.svm.SVC,"['liwc', 'sentiment']",1000
0.6467948717948717,"{'clf__classifier__C': 0.3, 'clf__classifier__gamma': 0.001, 'clf__classifier__kernel': 'poly'}","                   0          1  accuracy  macro avg  weighted avg
f1-score    0.702703   0.459016  0.616279   0.580860      0.597861
precision   0.629032   0.583333  0.616279   0.606183      0.609371
recall      0.795918   0.378378  0.616279   0.587148      0.616279
support    49.000000  37.000000  0.616279  86.000000     86.000000",2019-12-07 01:07:36.764471,sklearn.svm.SVC,"['liwc', 'sentiment']",1500
0.6466666666666666,"{'clf__classifier__C': 0.1, 'clf__classifier__gamma': 0.001, 'clf__classifier__kernel': 'poly'}","                   0          1  accuracy  macro avg  weighted avg
f1-score    0.733333   0.384615  0.627907   0.558974      0.583304
precision   0.619718   0.666667  0.627907   0.643192      0.639917
recall      0.897959   0.270270  0.627907   0.584115      0.627907
support    49.000000  37.000000  0.627907  86.000000     86.000000",2019-12-07 01:28:42.227927,sklearn.svm.SVC,"['liwc', 'sentiment']",2000
0.6366666666666666,"{'clf__classifier__C': 2.0, 'clf__classifier__gamma': 0.0001, 'clf__classifier__kernel': 'rbf'}","                   0          1  accuracy  macro avg  weighted avg
f1-score    0.728682   0.186047  0.593023   0.457364      0.495223
precision   0.587500   0.666667  0.593023   0.627083      0.621560
recall      0.959184   0.108108  0.593023   0.533646      0.593023
support    49.000000  37.000000  0.593023  86.000000     86.000000",2019-12-07 01:51:06.423077,sklearn.svm.SVC,"['liwc', 'sentiment']",5000
0.6770512820512821,"{'clf__classifier__C': 1.0, 'clf__classifier__gamma': 0.001, 'clf__classifier__kernel': 'poly'}","                   0          1  accuracy  macro avg  weighted avg
f1-score    0.672727   0.419355  0.581395   0.546041      0.563718
precision   0.606557   0.520000  0.581395   0.563279      0.569318
recall      0.755102   0.351351  0.581395   0.553227      0.581395
support    49.000000  37.000000  0.581395  86.000000     86.000000",2019-12-07 02:12:10.359298,sklearn.svm.SVC,"['liwc', 'sentiment', 'topic']",1000
0.6467948717948717,"{'clf__classifier__C': 0.3, 'clf__classifier__gamma': 0.001, 'clf__classifier__kernel': 'poly'}","                   0          1  accuracy  macro avg  weighted avg
f1-score    0.702703   0.459016  0.616279   0.580860      0.597861
precision   0.629032   0.583333  0.616279   0.606183      0.609371
recall      0.795918   0.378378  0.616279   0.587148      0.616279
support    49.000000  37.000000  0.616279  86.000000     86.000000",2019-12-07 02:33:03.409298,sklearn.svm.SVC,"['liwc', 'sentiment', 'topic']",1500
0.6466666666666666,"{'clf__classifier__C': 0.1, 'clf__classifier__gamma': 0.001, 'clf__classifier__kernel': 'poly'}","                   0          1  accuracy  macro avg  weighted avg
f1-score    0.733333   0.384615  0.627907   0.558974      0.583304
precision   0.619718   0.666667  0.627907   0.643192      0.639917
recall      0.897959   0.270270  0.627907   0.584115      0.627907
support    49.000000  37.000000  0.627907  86.000000     86.000000",2019-12-07 02:54:12.077438,sklearn.svm.SVC,"['liwc', 'sentiment', 'topic']",2000
0.6366666666666666,"{'clf__classifier__C': 2.0, 'clf__classifier__gamma': 0.0001, 'clf__classifier__kernel': 'rbf'}","                   0          1  accuracy  macro avg  weighted avg
f1-score    0.728682   0.186047  0.593023   0.457364      0.495223
precision   0.587500   0.666667  0.593023   0.627083      0.621560
recall      0.959184   0.108108  0.593023   0.533646      0.593023
support    49.000000  37.000000  0.593023  86.000000     86.000000",2019-12-07 03:16:37.569668,sklearn.svm.SVC,"['liwc', 'sentiment', 'topic']",5000
0.6362820512820513,"{'clf__classifier__C': 0.1, 'clf__classifier__gamma': 0.001, 'clf__classifier__kernel': 'poly'}","                   0          1  accuracy  macro avg  weighted avg
f1-score    0.699187   0.244898  0.569767   0.472042      0.503737
precision   0.581081   0.500000  0.569767   0.540541      0.546197
recall      0.877551   0.162162  0.569767   0.519857      0.569767
support    49.000000  37.000000  0.569767  86.000000     86.000000",2019-12-07 03:38:57.684390,sklearn.svm.SVC,"['liwc', 'sentiment', 'topic', 'mood']",1000
0.6261538461538462,"{'clf__classifier__C': 0.1, 'clf__classifier__gamma': 0.001, 'clf__classifier__kernel': 'poly'}","                   0          1  accuracy  macro avg  weighted avg
f1-score    0.704918   0.280000  0.581395   0.492459      0.522104
precision   0.589041   0.538462  0.581395   0.563751      0.567280
recall      0.877551   0.189189  0.581395   0.533370      0.581395
support    49.000000  37.000000  0.581395  86.000000     86.000000",2019-12-07 04:01:34.602111,sklearn.svm.SVC,"['liwc', 'sentiment', 'topic', 'mood']",1500
0.6364102564102564,"{'clf__classifier__C': 0.1, 'clf__classifier__gamma': 0.001, 'clf__classifier__kernel': 'poly'}","                   0          1  accuracy  macro avg  weighted avg
f1-score    0.724409   0.222222  0.593023   0.473316      0.508352
precision   0.589744   0.625000  0.593023   0.607372      0.604912
recall      0.938776   0.135135  0.593023   0.536955      0.593023
support    49.000000  37.000000  0.593023  86.000000     86.000000",2019-12-07 04:24:25.082745,sklearn.svm.SVC,"['liwc', 'sentiment', 'topic', 'mood']",2000
0.6315384615384615,"{'clf__classifier__C': 2.0, 'clf__classifier__gamma': 0.0001, 'clf__classifier__kernel': 'rbf'}","                   0          1  accuracy  macro avg  weighted avg
f1-score    0.728682   0.186047  0.593023   0.457364      0.495223
precision   0.587500   0.666667  0.593023   0.627083      0.621560
recall      0.959184   0.108108  0.593023   0.533646      0.593023
support    49.000000  37.000000  0.593023  86.000000     86.000000",2019-12-07 04:48:26.162067,sklearn.svm.SVC,"['liwc', 'sentiment', 'topic', 'mood']",5000
0.6616666666666666,"{'clf__classifier__C': 0.1, 'clf__classifier__gamma': 0.001, 'clf__classifier__kernel': 'poly'}","                   0          1  accuracy  macro avg  weighted avg
f1-score    0.721311   0.320000  0.604651   0.520656      0.548654
precision   0.602740   0.615385  0.604651   0.609062      0.608180
recall      0.897959   0.216216  0.604651   0.557088      0.604651
support    49.000000  37.000000  0.604651  86.000000     86.000000",2019-12-07 05:10:02.925344,sklearn.svm.SVC,"['liwc', 'sentiment', 'topic', 'moodChange']",1000
0.6516666666666666,"{'clf__classifier__C': 0.1, 'clf__classifier__gamma': 0.001, 'clf__classifier__kernel': 'poly'}","                   0          1  accuracy  macro avg  weighted avg
f1-score    0.710744   0.313725  0.593023   0.512235      0.539934
precision   0.597222   0.571429  0.593023   0.584325      0.586125
recall      0.877551   0.216216  0.593023   0.546884      0.593023
support    49.000000  37.000000  0.593023  86.000000     86.000000",2019-12-07 05:32:17.758649,sklearn.svm.SVC,"['liwc', 'sentiment', 'topic', 'moodChange']",1500
0.6415384615384615,"{'clf__classifier__C': 0.1, 'clf__classifier__gamma': 0.001, 'clf__classifier__kernel': 'poly'}","                   0          1  accuracy  macro avg  weighted avg
f1-score    0.731707   0.326531  0.616279   0.529119      0.557387
precision   0.608108   0.666667  0.616279   0.637387      0.633302
recall      0.918367   0.216216  0.616279   0.567292      0.616279
support    49.000000  37.000000  0.616279  86.000000     86.000000",2019-12-07 05:54:43.576510,sklearn.svm.SVC,"['liwc', 'sentiment', 'topic', 'moodChange']",2000
0.6417948717948718,"{'clf__classifier__C': 2.0, 'clf__classifier__gamma': 0.0001, 'clf__classifier__kernel': 'rbf'}","                   0          1  accuracy  macro avg  weighted avg
f1-score    0.734375   0.227273  0.604651   0.480824      0.516203
precision   0.594937   0.714286  0.604651   0.654611      0.646285
recall      0.959184   0.135135  0.604651   0.547159      0.604651
support    49.000000  37.000000  0.604651  86.000000     86.000000",2019-12-07 06:18:00.271463,sklearn.svm.SVC,"['liwc', 'sentiment', 'topic', 'moodChange']",5000
