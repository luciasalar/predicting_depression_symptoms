#Literature

* Detecting depression and mental illness on social media: an integrative review

This review shows scores of all the models 
---

* Predicting Depression via Social Media 

For each set of behavioral measures, we obtained daily measurements per user, which helped us construct one time series per measure per user, over the entire one year of Twitter history. Next, we developed a series of numbers from each of these time series for a given user, to be used eventually in constructing feature vectors for the depression prediction framework. Note that these time series features take into account the aggregated value over the yearlong period (given by mean), as well as its trend of change. 

This work use temporal feature 
---

* Quantifying Mental Health Signals in Twitter

LIWC
language modeling

* Recognizing Depression from Twitter Activity

Name Description

bag of words Frequencies of words used in the tweet

topic Ratio of tweet topics found by LDA [5]

positive Ratio of positive-affect words contained in the tweet

negative Ratio of negative-affect words contained in the tweet

hour Hourly posting frequency

tweet frequency Tweets per day

num. of words Average number of words per tweet
RT Overall retweet rate

mention Overall mention rate

URL Ratio of tweets containing a URL

followee Number of users following

follower Number of users followed

* Characterizing and Predicting Postpartum Depression
from Shared Facebook Data

LIWC 

affect

number of likes, comment

activity signal 

* Multi-Task Learning for Mental Health

using Social Media Text 

neural network 

embeddings 

* The Role of Personality, Age and Gender in Tweeting about Mental Illnesses
Random - .5 .5 .5

Age 1 .557 .742 .801

Gender 1 .559 .513 .522

Age + Gender 2 .590 .747 .8

Big5 5 .784 .813 .777

Age + Gender + Big5 7 .783 .844 .806

Affect + Intensity 2 .583 .519 .559

LIWC 64 .824 .854 .781

Topics 2000 .851 .901 .819

Unigrams 5432 .858 .911 .809

1-3 grams 12677 .859 .917 .812



This work has an accuracy of 0.9 but it's cheating because it uses big 5
--- 

* Forecasting the onset and course of mental illness with Twitter data

ANEW unigram sentiment instruments

LIWC 2007

labMT

word_count 

De Choudhury et al.8 looked at all of a given user’s tweets in a single day, and aggregated those data into per-person, per-day units of observation. In this report we have followed the convention of aggregated “user-days” as a primary unit of analysis, rather than try to categorize a person’s entire history, or analyze each individual tweet. In our own previous research, however, we have found that many Twitter users do not generate enough daily content to make for robust unigram sentiment analysis43. For completeness, we conducted analyses using both daily and weekly units of observation

Accordingly, state-space models, which use observable data to estimate the status of a latent, or hidden, variable over time, may provide useful insights. We trained a two-state Hidden Markov Model (HMM) to detect differential changes between affected and healthy groups over time. We used the hmmlearn Python module44 to fit emission and transition matrices (using expectation-maximization) and hidden state sequence (using the Viterbi path algorithm); this module also provided mean parameter estimates for all predictors, for each latent state.

The use of HMM presents an interpretability challenge: how to know whether resulting latent states have any relationship to the clinical condition of interest? Consider the case of depression: Finding evidence that HMM had, in fact, recovered two states from our data that closely resembled the depressed and healthy classes was prerequisite to making any inferences based on HMM output. We addressed this issue by comparing HMM output with mean differences between depressed and healthy observations in the raw data. If the directions of the differences between HMM mean parameter estimates generally agree with the true differences in the data, this provides evidence that the two sample groups in our data (depressed and healthy) are well-characterized by HMM latent states. For example, if depressed observations contained more sad words on average than healthy observations (variable name: “LIWC_sad”), then the HMM state with the higher LIWC_sad estimate is more likely to be the depressed one, given that HMM does track depression (i.e., the latent states generated by HMM map onto “depressed” and “healthy”).

This work has an accuracy of 0.87 and it does an analysis with HMM in the depressed and healthy group (I think this work is similar to Maria's suggestion)
--- 

## Our baseline
Base on the above literature, our baseline should include

LIWC

number of post

ANEW unigram sentiment instruments

labMT

word_count

demographic info

## Novelty in our model

* dynamic mood state
* dynamic mood transitions

These are not being considered in the existing literature